# -*- coding: utf-8 -*-
from __future__ import annotations

"""
Humanities Doc Toolkit - Classifier engine (v0.1)

ç›®æ ‡ï¼š
- å°½é‡å¤åˆ» Document Classifier v3.1 çš„â€œç”¨æˆ·ä½“éªŒä¸å¯æ ¸å¯¹æ€§â€ï¼š
  * æ‰«æ -> PDFæå–(æŒ‰é¡µèŒƒå›´/æœ€å°é•¿åº¦) -> AIåˆ†ç±»(å¤škeyè½®è¯¢) -> ç½®ä¿¡åº¦è¿‡æ»¤ -> å®‰å…¨ç§»åŠ¨(å¯é€‰å¤‡ä»½)
  * tqdm è¿›åº¦æ¡ + é™é»˜/é”™è¯¯å¯è§
  * æ‘˜è¦æŠ¥å‘Šï¼ˆå„æ–‡ä»¶å¤¹è®¡æ•°ã€å¤±è´¥/ä½ç½®ä¿¡åº¦ç»Ÿè®¡ï¼‰
  * è¯¦ç»†æ—¥å¿—ï¼šJSONï¼ˆå…¨é‡å­—æ®µï¼‰ + TXTï¼ˆç§»åŠ¨æ¸…å•ï¼‰ + è¿è¡Œæ—¥å¿—æ–‡ä»¶
- ä¸å·¥å…·é“¾è§„èŒƒå¯¹é½ï¼šå…±äº« global.yaml çš„ ai_servicesï¼›classifier.yaml æ”¾å·¥å…·å·®å¼‚åŒ–é…ç½®
- å…¼å®¹æ—§ v3.1 é…ç½®ç»“æ„ ai.servicesï¼šç”± loader è¿›è¡Œæ˜ å°„ï¼ˆai -> ai_servicesï¼‰[2][1]
"""

import os
import re
import json
import time
import shutil
import logging
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

import yaml
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from tqdm import tqdm

from ..config.loader import load_merged_config  # loader å·²æä¾› ai->ai_services å…¼å®¹æ˜ å°„
from ..common.logging_utils import setup_logger


PROJECT_NAME = "Humanities Doc Toolkit - Classifier"
VERSION = "0.1"


class ClassificationMode(Enum):
    PREDEFINED = "predefined"
    DYNAMIC = "dynamic"
    HYBRID = "hybrid"


class ProcessingStatus(Enum):
    PENDING = "å¾…å¤„ç†"
    SCANNING = "æ‰«æä¸­"
    EXTRACTING = "æå–ä¸­"
    ANALYZING = "åˆ†æä¸­"
    CLASSIFYING = "åˆ†ç±»ä¸­"
    MOVING = "ç§»åŠ¨ä¸­"
    COMPLETED = "å·²å®Œæˆ"
    FAILED = "å¤±è´¥"
    SKIPPED = "è·³è¿‡"
    LOW_CONFIDENCE = "ç½®ä¿¡åº¦è¿‡ä½"


@dataclass
class ClassificationResult:
    folder: str
    confidence: float
    reasoning: str
    source: str  # ai / keyword / predefined


@dataclass
class DocumentInfo:
    path: str
    filename: str
    size_mb: float
    pages: int
    content_length: int
    status: ProcessingStatus
    classification: Optional[ClassificationResult] = None
    error: Optional[str] = None
    processing_time: float = 0.0
    moved_to: Optional[str] = None
    planned_to: Optional[str] = None  # âœ… dry-run è®¡åˆ’ç›®æ ‡è·¯å¾„


# ----------------------------
# Logging (å¯¹é½ v3.1ï¼šæ–‡ä»¶+æ§åˆ¶å°ï¼Œä¸”æ”¯æŒè½®è½¬é…ç½®) [2][1]
# ----------------------------
def _setup_run_logging(cfg: Dict[str, Any]) -> Tuple[logging.Logger, Path]:
    log_cfg = cfg.get("logging", {}) if isinstance(cfg.get("logging", {}), dict) else {}
    level = str(log_cfg.get("level", "INFO")).upper()

    # v3.1: paths.log_folder [1]
    paths = cfg.get("paths", {}) if isinstance(cfg.get("paths", {}), dict) else {}
    log_dir = Path(paths.get("log_folder", "./logs"))
    log_dir.mkdir(parents=True, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"classifier_{ts}.log"

    logger = logging.getLogger("hdt-classifier")
    logger.setLevel(getattr(logging, level, logging.INFO))
    logger.handlers.clear()

    # æ§åˆ¶å°è¾“å‡ºï¼ˆå¯å…³ï¼‰
    enable_console = bool(log_cfg.get("enable_console_logging", True))
    fmt = log_cfg.get("log_format", "%(asctime)s - %(levelname)s - [%(threadName)s] - %(message)s")
    formatter = logging.Formatter(fmt)

    if enable_console:
        sh = logging.StreamHandler()
        sh.setFormatter(formatter)
        logger.addHandler(sh)

    # æ–‡ä»¶è¾“å‡ºï¼ˆå¯å…³ï¼‰
    enable_file = bool(log_cfg.get("enable_file_logging", True) or log_cfg.get("enable_file_logging", False) or log_cfg.get("enable_file_logging", True))
    if enable_file:
        # ç®€åŒ–ï¼šä¸å¼•å…¥ RotatingFileHandler ä¹Ÿå¯ï¼›ä½† v3.1 é…ç½®æä¾›è½®è½¬å‚æ•° [1]ã€‚
        # è¿™é‡Œç›´æ¥å†™ä¸€ä¸ªä¼šè¯ä¸€ä¸ªæ–‡ä»¶ï¼Œé…åˆ max_log_file_size_mb å¯åç»­å‡çº§åˆ° RotatingFileHandlerã€‚
        fh = logging.FileHandler(log_file, encoding="utf-8")
        fh.setFormatter(formatter)
        logger.addHandler(fh)

    logger.info(f"ğŸ“Š {PROJECT_NAME} v{VERSION} - æ—¥å¿—å¯åŠ¨")
    return logger, log_dir


# ----------------------------
# PDF extract (å¤åˆ» v3.1ï¼šPyPDF2 é¡µç èŒƒå›´ã€æœ€å°å†…å®¹é•¿åº¦ã€å…ƒæ•°æ®å¯é€‰) [2][1]
# ----------------------------
class PDFExtractor:
    """
    æå–ç­–ç•¥ï¼ˆautoï¼‰ï¼š
    1) ä¼˜å…ˆ PyMuPDFï¼ˆfitzï¼‰ï¼šé€Ÿåº¦å¿«ã€å…¼å®¹æ€§é€šå¸¸æ›´å¥½ï¼ˆä¸ä½  renamer ä¸€è‡´ï¼‰
    2) å›é€€ PyPDF2ï¼šä¿æŒ v3.1 çš„é€é¡µ extract_text é€»è¾‘ä¸é¡µèŒƒå›´æ§åˆ¶[2]

    åŒæ—¶ï¼šå®Œå…¨å±è”½ PyPDF2 åœ¨æŸäº›PDFå­—ä½“å¼‚å¸¸æ—¶äº§ç”Ÿçš„â€œunknown widthsâ€å™ªå£°è¾“å‡ºã€‚
    """

    def __init__(self, cfg: Dict[str, Any], logger: logging.Logger):
        self.cfg = cfg
        self.logger = logger
        self.pdf_cfg = cfg.get("pdf_processing", {}) if isinstance(cfg.get("pdf_processing", {}), dict) else {}

        self.page_range_start = int(self.pdf_cfg.get("page_range_start", 1))
        self.max_pages = int(self.pdf_cfg.get("max_pages_per_file", 20))
        self.min_len = int(self.pdf_cfg.get("min_content_length", 100))

        extractor_cfg = self.pdf_cfg.get("extractor", {}) if isinstance(self.pdf_cfg.get("extractor", {}), dict) else {}
        self.engine = str(extractor_cfg.get("engine", "auto")).lower()  # auto|pymupdf|pypdf2
        self.suppress_warnings = bool(extractor_cfg.get("suppress_warnings", True))
        self.silence_stderr = bool(extractor_cfg.get("silence_stderr", True))
        self.fallback = bool(extractor_cfg.get("fallback_to_other_engine", True))

    def extract(self, doc: DocumentInfo) -> Tuple[str, bool]:
        doc.status = ProcessingStatus.EXTRACTING

        # engine å†³ç­–
        engines: List[str]
        if self.engine == "pymupdf":
            engines = ["pymupdf"]
        elif self.engine == "pypdf2":
            engines = ["pypdf2"]
        else:
            engines = ["pymupdf", "pypdf2"]  # autoï¼šä¼˜å…ˆ pymupdfï¼Œå¤±è´¥å†å›é€€

        last_err: Optional[str] = None

        for eng in engines:
            content = ""
            ok = False
            try:
                if eng == "pymupdf":
                    content, ok = self._extract_with_pymupdf(doc)
                else:
                    content, ok = self._extract_with_pypdf2(doc)

                if ok and len(content) >= self.min_len:
                    doc.content_length = len(content)
                    return content, True

                last_err = doc.error or f"{eng} æå–å¤±è´¥/å†…å®¹è¿‡çŸ­"
                if not self.fallback:
                    break

            except Exception as e:
                last_err = f"{eng} æå–å¼‚å¸¸: {e}"
                doc.error = last_err
                if not self.fallback:
                    break

        doc.error = last_err or "æå–å¤±è´¥"
        return "", False

    def _extract_with_pymupdf(self, doc: DocumentInfo) -> Tuple[str, bool]:
        try:
            import fitz  # PyMuPDF
        except Exception as e:
            doc.error = "ç¼ºå°‘ä¾èµ– PyMuPDFï¼ˆè¯· pip install PyMuPDFï¼‰"
            self.logger.error(f"ç¼ºå°‘ PyMuPDF: {e}")
            return "", False

        try:
            parts: List[str] = []
            pdf = fitz.open(doc.path)
            total_pages = pdf.page_count
            doc.pages = total_pages

            start = max(1, self.page_range_start) - 1
            if self.max_pages == -1:
                end = total_pages
            else:
                end = min(start + max(1, self.max_pages), total_pages)

            self.logger.debug(f"{doc.filename}: [PyMuPDF] æå–é¡µç  {start+1}-{end}/{total_pages}")

            for i in range(start, end):
                try:
                    t = pdf[i].get_text() or ""
                    if t.strip():
                        parts.append(t.strip())
                except Exception as pe:
                    self.logger.warning(f"{doc.filename}: [PyMuPDF] ç¬¬{i+1}é¡µæå–å¤±è´¥: {pe}")

            pdf.close()
            content = self._clean(" ".join(parts))
            if len(content) < self.min_len:
                doc.error = f"[PyMuPDF] å†…å®¹è¿‡çŸ­: {len(content)} < {self.min_len}"
                return "", False
            return content, True

        except Exception as e:
            doc.error = f"[PyMuPDF] æå–å¤±è´¥: {e}"
            self.logger.error(f"{doc.filename}: [PyMuPDF] å†…å®¹æå–å¤±è´¥: {e}")
            return "", False

    def _extract_with_pypdf2(self, doc: DocumentInfo) -> Tuple[str, bool]:
        try:
            import PyPDF2  # ä¸ v3.1 ä¸€è‡´[2]
        except Exception as e:
            doc.error = "ç¼ºå°‘ä¾èµ– PyPDF2ï¼ˆè¯· pip install PyPDF2ï¼‰"
            self.logger.error(f"ç¼ºå°‘ PyPDF2: {e}")
            return "", False

        # ä¸¤å±‚é™å™ªï¼šlogging + stderrï¼ˆv3.1 ä¸­ä¹Ÿæœ‰â€œé™é»˜å¤„ç†â€ç†å¿µï¼Œä½†è¿™é‡Œä»…å¯¹æå–ç¯èŠ‚ç”Ÿæ•ˆï¼‰[2]
        import logging as _logging
        from contextlib import redirect_stderr
        from io import StringIO

        if self.suppress_warnings:
            _logging.getLogger("PyPDF2").setLevel(_logging.ERROR)

        stderr_buf = StringIO()
        stderr_ctx = redirect_stderr(stderr_buf) if self.silence_stderr else None

        try:
            content_parts: List[str] = []

            if stderr_ctx:
                with stderr_ctx:
                    content_parts = self._pypdf2_read_pages(PyPDF2, doc)
            else:
                content_parts = self._pypdf2_read_pages(PyPDF2, doc)

            content = self._clean(" ".join(content_parts))
            doc.content_length = len(content)

            if len(content) < self.min_len:
                doc.error = f"[PyPDF2] å†…å®¹è¿‡çŸ­: {len(content)} < {self.min_len}"
                return "", False

            return content, True

        except Exception as e:
            doc.error = f"[PyPDF2] æå–å¤±è´¥: {e}"
            self.logger.error(f"{doc.filename}: [PyPDF2] å†…å®¹æå–å¤±è´¥: {e}")
            return "", False

    def _pypdf2_read_pages(self, PyPDF2, doc: DocumentInfo) -> List[str]:
        parts: List[str] = []
        with open(doc.path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            total_pages = len(reader.pages)
            doc.pages = total_pages

            start = max(1, self.page_range_start) - 1
            if self.max_pages == -1:
                end = total_pages
            else:
                end = min(start + max(1, self.max_pages), total_pages)

            self.logger.debug(f"{doc.filename}: [PyPDF2] æå–é¡µç  {start+1}-{end}/{total_pages}")

            for i in range(start, end):
                try:
                    t = reader.pages[i].extract_text() or ""
                    if t.strip():
                        parts.append(t.strip())
                except Exception as pe:
                    # v3.1 ä¸­å¯¹å•é¡µå¤±è´¥æ˜¯ warning å¹¶ç»§ç»­[2]
                    self.logger.warning(f"{doc.filename}: [PyPDF2] ç¬¬{i+1}é¡µæå–å¤±è´¥: {pe}")
        return parts

    def _clean(self, content: str) -> str:
        # v3.1 æœ‰æ¸…ç†ç©ºç™½ä¸ç‰¹æ®Šç¬¦å·çš„å¤„ç†ï¼Œè¿™é‡Œå…ˆåšè½»é‡æ¸…æ´—[2]
        content = re.sub(r"\s+", " ", content)
        return content.strip()


# ----------------------------
# Folder selection (å¤åˆ» v3.1ï¼šé¢„è®¾/åŠ¨æ€/æ··åˆ) [2][1]
# ----------------------------
class FolderPolicy:
    def __init__(self, cfg: Dict[str, Any], logger: logging.Logger):
        self.cfg = cfg
        self.logger = logger
        self.mode = ClassificationMode.HYBRID

    def set_mode(self, mode: ClassificationMode):
        self.mode = mode

    def scan_target_folders(self, output_path: str) -> List[str]:
        p = Path(output_path)
        p.mkdir(parents=True, exist_ok=True)
        return [x.name for x in p.iterdir() if x.is_dir()]

    def predefined_folders(self) -> List[str]:
        predefined = self.cfg.get("classification", {}).get("predefined_categories", {})
        return list(predefined.keys()) if isinstance(predefined, dict) else []

    def available(self, existing: List[str]) -> List[str]:
        if self.mode == ClassificationMode.PREDEFINED:
            return self.predefined_folders()
        if self.mode == ClassificationMode.DYNAMIC:
            return existing
        return sorted(set(existing) | set(self.predefined_folders()))


# ----------------------------
# Safe move + optional backup (å¤åˆ» v3.1 SafeFileManager + backup å¼€å…³) [2][1]
# ----------------------------
class SafeFileManager:
    def __init__(self, cfg: Dict[str, Any], logger: logging.Logger):
        self.cfg = cfg
        self.logger = logger
        fm = cfg.get("file_management", {}) if isinstance(cfg.get("file_management", {}), dict) else {}
        self.safety = fm.get("safety", {}) if isinstance(fm.get("safety", {}), dict) else {}
        self.ops = fm.get("operations", {}) if isinstance(fm.get("operations", {}), dict) else {}

        # æ³¨æ„ï¼šä½ æ—§ config æœ‰ flase æ‹¼å†™é”™è¯¯ [1]ï¼Œè¿™é‡Œåšå¥å£®è§£æ
        self.enable_backup = self._as_bool(self.safety.get("enable_backup", False))
        self.backup_folder = Path(self.safety.get("backup_folder", "./backups"))
        self.backup_folder.mkdir(parents=True, exist_ok=True)

        self.conflict = str(self.ops.get("conflict_resolution", "rename")).lower()

    def _as_bool(self, v: Any) -> bool:
        if isinstance(v, bool):
            return v
        if isinstance(v, str):
            return v.strip().lower() in {"true", "1", "yes", "y"}
        return bool(v)

    def _resolve_conflict(self, target: Path) -> Path:
        if self.conflict != "rename":
            return target
        base = target.with_suffix("")
        ext = target.suffix
        c = 1
        out = target
        while out.exists():
            out = Path(f"{base}_{c:03d}{ext}")
            c += 1
        return out

    def _backup(self, src: Path) -> Optional[Path]:
        if not self.enable_backup:
            return None
        try:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            dst = self.backup_folder / f"{ts}_{src.name}"
            shutil.copy2(src, dst)
            self.logger.info(f"å¤‡ä»½åˆ›å»º: {dst}")
            return dst
        except Exception as e:
            self.logger.warning(f"å¤‡ä»½å¤±è´¥: {src}: {e}")
            return None

    def move_to_exact(self, src: str, dst: str) -> Tuple[bool, str]:
        """
        ä¸¥æ ¼æŒ‰æŒ‡å®šç›®æ ‡è·¯å¾„ç§»åŠ¨ï¼Œç”¨äº apply é˜¶æ®µå¤ç° dry-run çš„ planned_toã€‚
        æ³¨æ„ï¼šå¦‚æœ dst å·²å­˜åœ¨ï¼Œå°†è§†ä¸ºå¤±è´¥ï¼ˆæˆ–ä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œå†åšäºŒæ¬¡ resolveï¼‰ã€‚
        """
        try:
            src_p = Path(src)
            dst_p = Path(dst)
            dst_p.parent.mkdir(parents=True, exist_ok=True)

            if not src_p.exists():
                return False, f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src_p}"
            if dst_p.exists():
                return False, f"ç›®æ ‡å·²å­˜åœ¨(æ‹’ç»è¦†ç›–): {dst_p}"

            self._backup(src_p)
            shutil.move(str(src_p), str(dst_p))
            return True, str(dst_p)
        except Exception as e:
            return False, str(e)

    def move(self, src: str, folder: str, base_output: str) -> Tuple[bool, str]:
        try:
            src_p = Path(src)
            dst_dir = Path(base_output) / folder
            dst_dir.mkdir(parents=True, exist_ok=True)

            dst_p = dst_dir / src_p.name
            if dst_p.exists():
                dst_p = self._resolve_conflict(dst_p)

            self._backup(src_p)
            shutil.move(str(src_p), str(dst_p))
            return True, str(dst_p)
        except Exception as e:
            return False, str(e)

    def plan_target(self, src: str, folder: str, base_output: str) -> Tuple[bool, str]:
        """
        ä»…è®¡ç®—æœ€ç»ˆç›®æ ‡è·¯å¾„(å«å†²çªæ”¹åç­–ç•¥)ï¼Œä¸æ‰§è¡Œç§»åŠ¨ã€‚
        ç”¨äº dry-run é˜¶æ®µç”Ÿæˆ planned_toï¼Œä¿è¯ apply å¯å¤ç°ã€‚
        """
        try:
            src_p = Path(src)
            dst_dir = Path(base_output) / folder
            dst_dir.mkdir(parents=True, exist_ok=True)

            dst_p = dst_dir / src_p.name
            if dst_p.exists():
                dst_p = self._resolve_conflict(dst_p)

            return True, str(dst_p)
        except Exception as e:
            return False, str(e)

# ----------------------------
# AI Classifier (å¤škeyè½®è¯¢ï¼›Claude/Gemini ç‰¹æ®Šåè®®ï¼›å…¶ä½™ OpenAI-compatible)
# ä¸ä½  v3.1 çš„ multi-api è½®è¯¢æ€æƒ³ä¸€è‡´ [2]ï¼Œå¹¶ä¸å·¥å…·é“¾çš„ ai_services ç»“æ„å¯¹é½ [1]
# ----------------------------
class AIClassifier:
    def __init__(self, cfg: Dict[str, Any], logger: logging.Logger):
        self.cfg = cfg
        self.logger = logger
        self.timeout = int(cfg.get("ai_services", {}).get("api_request_timeout", 30))

        proc = cfg.get("processing", {}) if isinstance(cfg.get("processing", {}), dict) else {}
        conf = proc.get("confidence", {}) if isinstance(proc.get("confidence", {}), dict) else {}
        self.min_conf = float(conf.get("min_threshold", 0.3))
        self.skip_low = bool(conf.get("skip_low_confidence", True))
        err = proc.get("error_handling", {}) if isinstance(proc.get("error_handling", {}), dict) else {}
        self.retry_attempts = int(err.get("retry_attempts", 2))

        self.session = self._session()

        services = cfg.get("ai_services", {}).get("services", {})
        self.pool: List[Tuple[str, Dict[str, Any], Dict[str, Any]]] = []
        for name, scfg in services.items():
            if not isinstance(scfg, dict) or not scfg.get("enabled", False):
                continue
            for k in scfg.get("api_keys", []):
                if isinstance(k, dict) and k.get("enabled", False) and str(k.get("key", "")).strip():
                    self.pool.append((name, scfg, k))

        self._idx = 0
        if not self.pool:
            raise ValueError("æœªé…ç½®ä»»ä½•å¯ç”¨AIæœåŠ¡ï¼ˆai_services.services.*.enabled + api_keys[].enabledï¼‰")

        self.usage_stats: Dict[str, int] = {}

    def _session(self) -> requests.Session:
        s = requests.Session()
        retry = Retry(total=2, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])
        s.mount("https://", HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20))
        return s

    def _next_api(self) -> Tuple[str, Dict[str, Any], Dict[str, Any]]:
        item = self.pool[self._idx % len(self.pool)]
        self._idx += 1
        return item

    def classify(self, content: str, folders: List[str]) -> Optional[ClassificationResult]:
        preview = content[:4000] if len(content) > 4000 else content

        # âœ… ä¿®å¤ï¼šprompt ä¸­ä¸èƒ½å‡ºç°æœªè½¬ä¹‰çš„åŒå¼•å·ï¼ˆä½ å½“å‰ engine.py çš„é”™è¯¯å°±åœ¨è¿™é‡Œï¼‰[2]
        prompt = (
            "ä½ æ˜¯ä¸“é—¨å¤„ç†äººæ–‡å­¦ç§‘æ–‡çŒ®çš„åˆ†ç±»ä¸“å®¶ã€‚\n"
            "è¯·ä»ä¸‹åˆ—ã€å¯é€‰åˆ†ç±»æ–‡ä»¶å¤¹ã€‘ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªï¼Œå¹¶ç»™å‡ºç½®ä¿¡åº¦(0-1)ä¸ç®€çŸ­ç†ç”±ã€‚\n\n"
            "ã€å¯é€‰åˆ†ç±»æ–‡ä»¶å¤¹ã€‘:\n"
            + "\n".join([f"- {f}" for f in folders])
            + "\n\n"
            f"ã€æ–‡æ¡£å†…å®¹æ‘˜è¦ã€‘:\n{preview}\n\n"
            "åªè¾“å‡ºJSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–æ–‡æœ¬ï¼š\n"
            '{"folder":"...", "confidence":0.0, "reasoning":"..."}'
        )

        for _ in range(max(1, self.retry_attempts)):
            service_name, scfg, kcfg = self._next_api()
            api_id = f"{service_name}_{kcfg.get('name','key')}"
            self.usage_stats[api_id] = self.usage_stats.get(api_id, 0) + 1

            try:
                data = self._call(service_name, scfg, kcfg, prompt)
                if not data:
                    continue

                folder_raw = str(data.get("folder", "")).strip()
                confidence = float(data.get("confidence", 0.0) or 0.0)
                reasoning = str(data.get("reasoning", "")).strip()

                matched = self._match_folder(folder_raw, folders)
                if not matched:
                    continue

                if self.skip_low and confidence < self.min_conf:
                    return ClassificationResult(matched, confidence, reasoning, "ai_low_confidence")
                return ClassificationResult(matched, confidence, reasoning, "ai")

            except Exception as e:
                self.logger.warning(f"AIè°ƒç”¨å¤±è´¥({api_id}): {e}")
                continue

        return None

    def _match_folder(self, result: str, folders: List[str]) -> Optional[str]:
        r = result.strip().strip("\"'")
        rl = r.lower()
        for f in folders:
            if r == f or rl == f.lower():
                return f
        for f in folders:
            fl = f.lower()
            if rl in fl or fl in rl:
                return f
        return None

    def _safe_json(self, text: str) -> Optional[Dict[str, Any]]:
        if not text:
            return None
        t = text.strip()
        if t.startswith("```"):
            t = re.sub(r"^```[a-zA-Z]*\n", "", t).strip()
            t = t.rstrip("`").strip()
        if not (t.startswith("{") and t.endswith("}")):
            m = re.search(r"\{.*\}", t, re.DOTALL)
            if m:
                t = m.group(0)
        try:
            obj = json.loads(t)
            return obj if isinstance(obj, dict) else None
        except Exception:
            return None

    def _call(self, service_name: str, scfg: Dict[str, Any], kcfg: Dict[str, Any], prompt: str) -> Optional[Dict[str, Any]]:
        key = str(kcfg.get("key", "")).strip()
        base_url = str(scfg.get("base_url", "")).rstrip("/")
        model = scfg.get("model", "")
        max_tokens = int(scfg.get("max_tokens", 300))
        temperature = float(scfg.get("temperature", 0.1))

        # Claude
        if service_name == "claude" or "anthropic" in base_url:
            url = base_url if base_url.endswith("/v1/messages") else base_url + "/v1/messages"
            headers = {
                "x-api-key": key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            }
            payload = {
                "model": model or "claude-3-haiku-20240307",
                "max_tokens": max_tokens,
                "temperature": temperature,
                "messages": [{"role": "user", "content": prompt}],
            }
            r = self.session.post(url, headers=headers, json=payload, timeout=self.timeout)
            r.raise_for_status()
            data = r.json()
            text = ""
            if isinstance(data.get("content"), list) and data["content"]:
                text = data["content"][0].get("text", "")
            return self._safe_json(text)

        # Gemini
        if service_name == "gemini" or "generativelanguage.googleapis.com" in base_url:
            url = base_url
            if "key=" not in url:
                url = url + ("&" if "?" in url else "?") + f"key={key}"
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"temperature": temperature, "maxOutputTokens": max_tokens},
            }
            r = self.session.post(url, json=payload, timeout=self.timeout)
            r.raise_for_status()
            data = r.json()
            text = ""
            try:
                text = data["candidates"][0]["content"]["parts"][0]["text"]
            except Exception:
                text = ""
            return self._safe_json(text)

        # OpenAI-compatible
        url = base_url if base_url.endswith("/chat/completions") else base_url + "/chat/completions"
        headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„äººæ–‡å­¦ç§‘æ–‡æ¡£åˆ†ç±»ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt},
            ],
            "max_tokens": max_tokens,
            "temperature": temperature,
        }
        r = self.session.post(url, headers=headers, json=payload, timeout=self.timeout)
        r.raise_for_status()
        data = r.json()
        text = data["choices"][0]["message"]["content"]
        return self._safe_json(text)


# ----------------------------
# Report Generator (å¤åˆ» v3.1ï¼šæ‘˜è¦ + JSONè¯¦ç»†æ—¥å¿— + TXTç§»åŠ¨æ¸…å•) [2]
# ----------------------------
class ReportGenerator:
    def __init__(self):
        self.start_time = datetime.now()
        self.docs: List[DocumentInfo] = []
        self.folder_stats: Dict[str, int] = {}
        self.error_summary: Dict[str, int] = {}
        self.api_usage_stats: Dict[str, int] = {}

    def add(self, doc: DocumentInfo):
        self.docs.append(doc)
        if doc.status == ProcessingStatus.COMPLETED and doc.classification:
            f = doc.classification.folder
            self.folder_stats[f] = self.folder_stats.get(f, 0) + 1
        if doc.error:
            et = doc.error.split(":")[0]
            self.error_summary[et] = self.error_summary.get(et, 0) + 1

    def set_api_usage(self, stats: Dict[str, int]):
        self.api_usage_stats = dict(stats or {})

    def summary_text(self) -> str:
        total = len(self.docs)
        ok = len([d for d in self.docs if d.status == ProcessingStatus.COMPLETED])
        fail = len([d for d in self.docs if d.status == ProcessingStatus.FAILED])
        low = len([d for d in self.docs if d.status == ProcessingStatus.LOW_CONFIDENCE])
        dur = datetime.now() - self.start_time
        avg = sum(d.processing_time for d in self.docs) / max(1, total)

        lines = []
        lines.append("=" * 70)
        lines.append(f"ğŸ“Š {PROJECT_NAME} v{VERSION} å¤„ç†æŠ¥å‘Š")
        lines.append("=" * 70)
        lines.append(f"ğŸ•’ ç”¨æ—¶: {dur}")
        lines.append(f"ğŸ“ æ€»æ–‡æ¡£æ•°: {total}")
        lines.append(f"âœ… å®Œæˆ(å·²ç”Ÿæˆ planned_to): {ok}")
        lines.append(f"âŒ å¤±è´¥: {fail}")
        lines.append(f"âš ï¸ ä½ç½®ä¿¡åº¦/æœªç§»åŠ¨: {low}")
        lines.append(f"â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {avg:.2f} ç§’/æ–‡æ¡£")

        if self.folder_stats:
            lines.append("")
            lines.append("ğŸ“‚ åˆ†ç±»åˆ†å¸ƒ:")
            for folder, count in sorted(self.folder_stats.items(), key=lambda x: x[1], reverse=True):
                lines.append(f"   ğŸ“‚ {folder}: {count} ä¸ªæ–‡æ¡£")

        if self.api_usage_stats:
            lines.append("")
            lines.append("ğŸ¤– APIä½¿ç”¨ç»Ÿè®¡:")
            for api_id, count in sorted(self.api_usage_stats.items(), key=lambda x: x[1], reverse=True):
                lines.append(f"   ğŸ¤– {api_id}: {count} æ¬¡è°ƒç”¨")

        if self.error_summary:
            lines.append("")
            lines.append("âŒ é”™è¯¯ç±»å‹ç»Ÿè®¡:")
            for et, c in sorted(self.error_summary.items(), key=lambda x: x[1], reverse=True):
                lines.append(f"   âŒ {et}: {c} æ¬¡")

        lines.append("=" * 70)
        return "\n".join(lines)

    def save_json(self, log_dir: Path) -> Path:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out = log_dir / f"classification_details_{ts}.json"

        details = {
            "session_info": {
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_seconds": (datetime.now() - self.start_time).total_seconds(),
                "version": VERSION,
            },
            "statistics": {
                "total": len(self.docs),
                "successful": len([d for d in self.docs if d.status == ProcessingStatus.COMPLETED]),
                "failed": len([d for d in self.docs if d.status == ProcessingStatus.FAILED]),
                "low_confidence": len([d for d in self.docs if d.status == ProcessingStatus.LOW_CONFIDENCE]),
                "folder_stats": self.folder_stats,
                "api_usage_stats": self.api_usage_stats,
                "error_summary": self.error_summary,
            },
            "documents": [],
        }

        for d in self.docs:
            row = {
                "filename": d.filename,
                "path": d.path,
                "size_mb": d.size_mb,
                "pages": d.pages,
                "content_length": d.content_length,
                "status": d.status.value,
                "processing_time": d.processing_time,
                "planned_to": d.planned_to,   # âœ… æ–°å¢
                "moved_to": d.moved_to,
                "error": d.error,
            }
            if d.classification:
                row["classification"] = {
                    "folder": d.classification.folder,
                    "confidence": d.classification.confidence,
                    "reasoning": d.classification.reasoning,
                    "source": d.classification.source,
                }
            details["documents"].append(row)

        with out.open("w", encoding="utf-8") as f:
            json.dump(details, f, ensure_ascii=False, indent=2)
        return out

    def save_txt_moves(self, log_dir: Path) -> Path:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out = log_dir / f"move_list_{ts}.txt"

        ok_docs = [d for d in self.docs if d.status == ProcessingStatus.COMPLETED and d.classification]
        low_docs = [d for d in self.docs if d.status == ProcessingStatus.LOW_CONFIDENCE]
        fail_docs = [d for d in self.docs if d.status == ProcessingStatus.FAILED]

        with out.open("w", encoding="utf-8") as f:
            f.write(f"{PROJECT_NAME} v{VERSION} æ¸…å•\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("è¯´æ˜:\n")
            f.write("- planned_to å­˜åœ¨ => æœ¬æ¬¡ä¸º dry-run è®¡åˆ’ç§»åŠ¨(æœªæ‰§è¡Œç§»åŠ¨)\n")
            f.write("- moved_to å­˜åœ¨   => å·²æ‰§è¡Œç§»åŠ¨(æ¥è‡ª apply æˆ–æ—§ç‰ˆç›´æ¥ç§»åŠ¨)\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"âœ… å·²å®Œæˆåˆ†ç±»/è®¡åˆ’æˆ–å·²ç§»åŠ¨ ({len(ok_docs)}):\n")
            f.write("-" * 60 + "\n")
            for d in ok_docs:
                f.write(f"ğŸ“„ {d.filename}\n")
                f.write(f"   ğŸ“‚ åˆ†ç±»: {d.classification.folder}\n")
                f.write(f"   ğŸ¯ ç½®ä¿¡åº¦: {d.classification.confidence:.2f}\n")
                f.write(f"   ğŸ’­ ç†ç”±: {d.classification.reasoning}\n")
                if d.planned_to:
                    f.write(f"   ğŸ§¾ planned_to: {d.planned_to}\n")
                if d.moved_to:
                    f.write(f"   âœ… moved_to: {d.moved_to}\n")
                f.write("\n")

            if low_docs:
                f.write(f"\nâš ï¸ ä½ç½®ä¿¡åº¦/æœªçº³å…¥æ¸…å• ({len(low_docs)}):\n")
                f.write("-" * 60 + "\n")
                for d in low_docs:
                    f.write(f"ğŸ“„ {d.filename} - {d.error}\n")

            if fail_docs:
                f.write(f"\nâŒ å¤±è´¥ ({len(fail_docs)}):\n")
                f.write("-" * 60 + "\n")
                for d in fail_docs:
                    f.write(f"ğŸ“„ {d.filename} - {d.error}\n")

        return out


# ----------------------------
# Scanner (å¤åˆ» v3.1ï¼šæŒ‰å¤§å°æ’åºï¼Œå°æ–‡ä»¶ä¼˜å…ˆ) [2]
# ----------------------------
def scan_pdfs(cfg: Dict[str, Any], input_folder: str) -> List[DocumentInfo]:
    pdf_cfg = cfg.get("pdf_processing", {}) if isinstance(cfg.get("pdf_processing", {}), dict) else {}
    max_mb = float(pdf_cfg.get("max_file_size_mb", 1000))
    docs: List[DocumentInfo] = []

    for root, _, files in os.walk(input_folder):
        for fn in files:
            if not fn.lower().endswith(".pdf"):
                continue
            fp = Path(root) / fn
            try:
                size_mb = fp.stat().st_size / (1024 * 1024)
                if max_mb > 0 and size_mb > max_mb:
                    continue
                docs.append(DocumentInfo(
                    path=str(fp),
                    filename=fn,
                    size_mb=size_mb,
                    pages=0,
                    content_length=0,
                    status=ProcessingStatus.PENDING
                ))
            except Exception:
                continue

    docs.sort(key=lambda d: d.size_mb)
    return docs


# ----------------------------
# Engine entry
# ----------------------------
class ClassifierEngine:
    def __init__(self, global_config: str, tool_config: str):
        self.cfg = load_merged_config(global_config, tool_config)
        self.logger, self.log_dir = _setup_run_logging(self.cfg)

    def _select_mode(self) -> ClassificationMode:
        default = self.cfg.get("classification", {}).get("modes", {}).get("default_mode", "hybrid")
        mapping = {"predefined": "1", "dynamic": "2", "hybrid": "3"}
        default_choice = mapping.get(str(default).lower(), "3")

        print("\nğŸ“‚ é€‰æ‹©åˆ†ç±»æ¨¡å¼:")
        print("1. é¢„è®¾åˆ†ç±»æ¨¡å¼ï¼ˆé…ç½®é¢„å®šä¹‰åˆ†ç±»è§„åˆ™ï¼‰")
        print("2. åŠ¨æ€æ£€æµ‹æ¨¡å¼ï¼ˆæ‰«æç›®æ ‡ç›®å½•ç°æœ‰æ–‡ä»¶å¤¹ï¼‰")
        print("3. æ··åˆæ¨¡å¼ï¼ˆé¢„è®¾ + åŠ¨æ€åˆå¹¶ï¼Œæ¨èï¼‰")
        while True:
            c = input(f"è¯·é€‰æ‹© (1-3, é»˜è®¤={default_choice}): ").strip() or default_choice
            if c == "1":
                return ClassificationMode.PREDEFINED
            if c == "2":
                return ClassificationMode.DYNAMIC
            if c == "3":
                return ClassificationMode.HYBRID
            print("âŒ è¯·è¾“å…¥ 1-3")

    def _get_paths(self) -> Tuple[str, str]:
        paths = self.cfg.get("paths", {}) if isinstance(self.cfg.get("paths", {}), dict) else {}
        default_input = paths.get("input_folder", "")
        default_output = paths.get("output_folder", "")

        print("\nğŸ“ è·¯å¾„é…ç½®:")
        while True:
            ip = input(f"PDFæ–‡ä»¶å¤¹è·¯å¾„{f' (é»˜è®¤: {default_input})' if default_input else ''}: ").strip().strip('"') or default_input
            if ip and os.path.exists(ip):
                break
            print("âŒ è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

        op = input(f"åˆ†ç±»ç›®æ ‡è·¯å¾„{f' (é»˜è®¤: {default_output})' if default_output else ' (å›è½¦=./classified)'}: ").strip().strip('"') or default_output or "./classified"
        return ip, op

    def display_header(self):
        from ..__about__ import __title__, __version__, __author__, __email__, __github__

        print("=" * 70)
        print(f"ğŸ¯ {__title__} - Classifier v{__version__}")
        print(f"ğŸ‘¨â€ğŸ’» ä½œè€…: {__author__} | {__email__}")
        print(f"ğŸ”— {__github__}")
        print("-" * 70)
        print("ğŸ“ ä¸“é—¨é’ˆå¯¹äººæ–‡å­¦ç§‘çš„æ™ºèƒ½æ–‡çŒ®åˆ†ç±»ä¸å½’æ¡£å·¥å…·(å¯å¤æ ¸/ä½é£é™©)")
        print("æ ¸å¿ƒæµç¨‹: æ‰«æ â†’ æå– â†’ AIåˆ†ç±» â†’ ç½®ä¿¡åº¦è¿‡æ»¤ â†’ ç”Ÿæˆæ¸…å•/æ—¥å¿— [12]")
        print("å®‰å…¨ç­–ç•¥:")
        print("  1) é»˜è®¤ dry-runï¼šåªç”Ÿæˆ JSON/TXT æ¸…å•ï¼Œä¸ç§»åŠ¨æ–‡ä»¶ï¼ˆæ›´å®‰å…¨ï¼‰")
        print("  2) éœ€è¦ç§»åŠ¨æ—¶ï¼šè¿è¡Œ hdt-classifier-apply --log <classification_details_*.json>")
        print("é…ç½®æç¤º: å¤åˆ¶ configs/*.example.yaml åˆ°æ ¹ç›®å½•ç”Ÿæˆ global.yaml/classifier.yaml [2]")
        print("å®‰å…¨æç¤º: è¯·å‹¿æäº¤çœŸå® API Keyï¼›ä»“åº“åªæ”¾ example é…ç½® [2]")
        print("=" * 70)

    def _get_services_cfg(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡é…ç½®ï¼šå·¥å…·é“¾è§„èŒƒæ˜¯ ai_services.servicesï¼›
        å…¼å®¹ v3.1 çš„ ai.services ç»“æ„ [2][1]ã€‚
        """
        if isinstance(self.cfg.get("ai_services"), dict) and isinstance(self.cfg["ai_services"].get("services"), dict):
            return self.cfg["ai_services"]["services"]
        if isinstance(self.cfg.get("ai"), dict) and isinstance(self.cfg["ai"].get("services"), dict):
            return self.cfg["ai"]["services"]
        return {}

    def display_simplified_api_status(self) -> bool:
        """
        æ˜¾ç¤ºå¯ç”¨AIæœåŠ¡æ¦‚è§ˆï¼ˆå¤åˆ» v3.1 çš„ç®€åŒ–çŠ¶æ€æ˜¾ç¤ºï¼‰[2]ã€‚
        """
        services = self._get_services_cfg()
        if not services:
            print("âŒ é…ç½®ä¸­æœªæ‰¾åˆ° AI æœåŠ¡é…ç½®ï¼ˆai_services.servicesï¼‰")
            return False

        available = []
        print("\nğŸ¤– å¯ç”¨AIæœåŠ¡:")
        for name, scfg in services.items():
            if not isinstance(scfg, dict) or not scfg.get("enabled", False):
                continue

            keys = scfg.get("api_keys", []) if isinstance(scfg.get("api_keys", []), list) else []
            enabled_keys = [k for k in keys if isinstance(k, dict) and k.get("enabled", False) and str(k.get("key", "")).strip()]
            if not enabled_keys:
                continue

            model = scfg.get("model", "default")
            print(f"   âœ… {name.upper():<10} æ¨¡å‹: {model:<18} å¯†é’¥: {len(enabled_keys)}")
            available.append(name)

        if not available:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„AIæœåŠ¡ï¼ˆè¯·æ£€æŸ¥ enabled ä¸ api_keysï¼‰")
            return False

        return True

    def apply_moves_from_log(self, log_path: str) -> int:
        """
        æ ¹æ® dry-run ç”Ÿæˆçš„ classification_details_*.json æ‰§è¡Œç§»åŠ¨ã€‚
        ä¸¥æ ¼æŒ‰ planned_to è½ç›˜ï¼ˆå¯å¤æ ¸/å¯å¤ç°ï¼‰ã€‚
        """
        p = Path(log_path)
        if not p.exists():
            print(f"âŒ æ—¥å¿—ä¸å­˜åœ¨: {p}")
            return 1

        try:
            data = json.loads(p.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"âŒ æ—¥å¿—JSONè§£æå¤±è´¥: {e}")
            return 1

        docs = data.get("documents", [])
        if not isinstance(docs, list) or not docs:
            print("âŒ æ—¥å¿—ä¸­æ²¡æœ‰ documents")
            return 1

        mover = SafeFileManager(self.cfg, self.logger)

        ok, fail, skipped = 0, 0, 0
        for item in docs:
            try:
                status = item.get("status")
                src = item.get("path")
                planned_to = item.get("planned_to")

                if status != ProcessingStatus.COMPLETED.value:
                    skipped += 1
                    continue
                if not (src and planned_to):
                    skipped += 1
                    continue
                if not Path(src).exists():
                    fail += 1
                    self.logger.warning(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {src}")
                    continue

                ok2, msg = mover.move_to_exact(src, planned_to)
                if ok2:
                    ok += 1
                else:
                    fail += 1
                    self.logger.warning(f"ç§»åŠ¨å¤±è´¥: {src} -> {planned_to} | {msg}")

            except Exception as e:
                fail += 1
                self.logger.warning(f"ç§»åŠ¨å¼‚å¸¸: {e}")

        print(f"âœ… apply å®Œæˆ: æˆåŠŸç§»åŠ¨={ok}, å¤±è´¥={fail}, è·³è¿‡={skipped}")
        return 0 if fail == 0 else 1

    def display_ai_service_selection(self) -> Optional[str]:
        """
        é€‰æ‹©ä½¿ç”¨å“ªä¸ªæœåŠ¡ï¼š
        - é€‰æ‹©å•ä¸€æœåŠ¡ï¼šå°†å…¶å®ƒæœåŠ¡ enabled=False
        - æˆ–â€œå…¨éƒ¨æœåŠ¡è‡ªåŠ¨è½®è¯¢â€ï¼šä¿æŒåŸçŠ¶
        è¿”å›ï¼šé€‰ä¸­çš„æœåŠ¡åï¼ˆå•ä¸€ï¼‰æˆ– Noneï¼ˆè¡¨ç¤ºå…¨éƒ¨è½®è¯¢ï¼‰
        ï¼ˆå¤åˆ» v3.1 çš„ service selection äº¤äº’ï¼‰[2]ã€‚
        """
        services = self._get_services_cfg()

        available_services = []
        for name, scfg in services.items():
            if not isinstance(scfg, dict) or not scfg.get("enabled", False):
                continue
            keys = scfg.get("api_keys", []) if isinstance(scfg.get("api_keys", []), list) else []
            enabled_keys = [k for k in keys if isinstance(k, dict) and k.get("enabled", False) and str(k.get("key", "")).strip()]
            if enabled_keys:
                available_services.append({
                    "name": name,
                    "model": scfg.get("model", "default"),
                    "key_count": len(enabled_keys),
                })

        if not available_services:
            print("âŒ æ²¡æœ‰å¯ç”¨AIæœåŠ¡")
            return None

        # åªæœ‰ä¸€ä¸ªæœåŠ¡æ—¶é»˜è®¤ç›´æ¥ç”¨å®ƒ
        if len(available_services) == 1:
            s = available_services[0]["name"]
            print(f"ğŸ¤– å°†ä½¿ç”¨: {s.upper()}")
            return s

        print("\nğŸ¤– é€‰æ‹©AIæœåŠ¡:")
        for i, s in enumerate(available_services, 1):
            print(f"{i}. {s['name'].upper()} - æ¨¡å‹: {s['model']} ({s['key_count']}ä¸ªå¯†é’¥)")
        print(f"{len(available_services) + 1}. ä½¿ç”¨å…¨éƒ¨æœåŠ¡ï¼ˆè‡ªåŠ¨è½®è¯¢ï¼Œæ¨èï¼‰")

        default_choice = str(len(available_services) + 1)
        while True:
            choice = input(f"\nè¯·é€‰æ‹© (1-{len(available_services)+1}, é»˜è®¤={default_choice}): ").strip() or default_choice

            if choice == str(len(available_services) + 1):
                print("âœ… å°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨AIæœåŠ¡ï¼ˆè‡ªåŠ¨è½®è¯¢ï¼‰")
                return None

            try:
                idx = int(choice)
                if 1 <= idx <= len(available_services):
                    selected = available_services[idx - 1]["name"]
                    for name in services.keys():
                        services[name]["enabled"] = (name == selected)
                    print(f"âœ… å·²é€‰æ‹©: {selected.upper()}ï¼ˆå…¶å®ƒæœåŠ¡å·²ä¸´æ—¶ç¦ç”¨ï¼‰")
                    return selected
            except ValueError:
                pass

            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆé€‰é¡¹")

    def _open_file(self, p: Path):
        """è·¨å¹³å°æ‰“å¼€æ–‡ä»¶(ç”¨äºæ‰“å¼€ dry-run ç”Ÿæˆçš„ JSON æ¸…å•)"""
        try:
            import subprocess, platform
            sysname = platform.system()
            if sysname == "Windows":
                os.startfile(str(p))  # type: ignore[attr-defined]
            elif sysname == "Darwin":
                subprocess.run(["open", str(p)], check=False)
            else:
                subprocess.run(["xdg-open", str(p)], check=False)
        except Exception as e:
            self.logger.warning(f"æ‰“å¼€æ–‡ä»¶å¤±è´¥: {p} | {e}")

    def run_interactive(self, dry_run: bool = True) -> int:
        self.display_header()

        if not self.display_simplified_api_status():
            return 1
        self.display_ai_service_selection()

        mode = self._select_mode()
        input_path, output_path = self._get_paths()
        # 2) æ‰«æ
        docs = scan_pdfs(self.cfg, input_path)
        if not docs:
            print("âŒ æœªæ‰¾åˆ°å¯å¤„ç†çš„PDF")
            return 1

        policy = FolderPolicy(self.cfg, self.logger)
        policy.set_mode(mode)
        existing = policy.scan_target_folders(output_path)
        folders = policy.available(existing)
        if not folders:
            print("âŒ æ²¡æœ‰å¯ç”¨åˆ†ç±»æ–‡ä»¶å¤¹ï¼šè¯·åœ¨ç›®æ ‡ç›®å½•åˆ›å»ºæ–‡ä»¶å¤¹æˆ–é…ç½® predefined_categories")
            return 1

        extractor = PDFExtractor(self.cfg, self.logger)
        mover = SafeFileManager(self.cfg, self.logger)
        ai = AIClassifier(self.cfg, self.logger)
        report = ReportGenerator()

        # 3) å¤šçº¿ç¨‹è®¾ç½®ï¼ˆæ²¿ç”¨ v3.1 processing.multithreading.max_workersï¼‰[1][2]
        proc = self.cfg.get("processing", {}) if isinstance(self.cfg.get("processing", {}), dict) else {}
        mt = proc.get("multithreading", {}) if isinstance(proc.get("multithreading", {}), dict) else {}
        enable_mt = bool(mt.get("enabled", True))
        max_workers = int(mt.get("max_workers", 8))
        if not enable_mt:
            max_workers = 1

        print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(docs)} ä¸ªæ–‡æ¡£ (çº¿ç¨‹æ•°: {max_workers}) ...")
        print(f"ğŸ“‚ å¯é€‰åˆ†ç±»æ–‡ä»¶å¤¹æ•°: {len(folders)}")
        start = time.time()

        def handle_one(d: DocumentInfo) -> DocumentInfo:
            t0 = time.time()
            try:
                # 1) æå–
                d.status = ProcessingStatus.EXTRACTING
                content, ok = extractor.extract(d)
                if not ok:
                    d.status = ProcessingStatus.FAILED
                    return d

                # 2) åˆ†ç±»
                d.status = ProcessingStatus.CLASSIFYING
                res = ai.classify(content, folders)
                if not res:
                    d.status = ProcessingStatus.LOW_CONFIDENCE
                    d.error = "AIæœªè¿”å›å¯åŒ¹é…åˆ†ç±»æˆ–ç½®ä¿¡åº¦è¿‡ä½"
                    return d

                d.classification = res

                if res.source == "ai_low_confidence":
                    d.status = ProcessingStatus.LOW_CONFIDENCE
                    d.error = f"ç½®ä¿¡åº¦ {res.confidence:.2f} ä½äºé˜ˆå€¼ï¼Œä¿æŒåŸä½"
                    return d

                # 3) åªæ”¯æŒ dry-run ç”Ÿæˆ planned_toï¼ˆæ¨èçš„å®‰å…¨æ¨¡å¼ï¼‰[2]
                if dry_run:
                    ok2, planned = mover.plan_target(d.path, res.folder, output_path)
                    if ok2:
                        d.status = ProcessingStatus.COMPLETED
                        d.planned_to = planned
                        d.moved_to = None
                    else:
                        d.status = ProcessingStatus.FAILED
                        d.error = planned
                    return d

                # å¦‚æœä½ çœŸçš„æƒ³æ”¯æŒâ€œç›´æ¥ç§»åŠ¨â€ï¼Œè¯·ä¸è¦åœ¨è¿™é‡Œåšï¼›
                # ç»Ÿä¸€èµ° apply_moves_from_log()ï¼Œä¿è¯å¯å¤æ ¸ã€å¯å›æ»šã€‚
                d.status = ProcessingStatus.SKIPPED
                d.error = "å½“å‰äº¤äº’æ¨¡å¼ä¸æ”¯æŒç›´æ¥ç§»åŠ¨ï¼›è¯·ä½¿ç”¨ applyï¼ˆä» JSON æ¸…å•æ‰§è¡Œç§»åŠ¨ï¼‰"
                return d

            except Exception as e:
                d.status = ProcessingStatus.FAILED
                d.error = str(e)
                return d
            finally:
                d.processing_time = time.time() - t0

        def _plan_summary(docs_list: List[DocumentInfo]) -> Dict[str, int]:
            from collections import defaultdict
            from pathlib import Path as _Path
            dd = defaultdict(int)
            for d in docs_list:
                if d.status == ProcessingStatus.COMPLETED and d.planned_to:
                    dd[_Path(d.planned_to).parent.name] += 1
            return dict(dd)

        # çº¿ç¨‹æ± æ‰§è¡Œ
        results: List[DocumentInfo] = []
        if max_workers == 1:
            for d in tqdm(docs, desc="å¤„ç†è¿›åº¦"):
                r = handle_one(d)
                report.add(r)
                results.append(r)
        else:
            with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="ClassifierWorker") as ex:
                futs = {ex.submit(handle_one, d): d for d in docs}
                for fut in tqdm(as_completed(futs), total=len(futs), desc="å¤„ç†è¿›åº¦"):
                    r = fut.result()
                    report.add(r)
                    results.append(r)

        dur = time.time() - start
        completed = [d for d in results if d.status == ProcessingStatus.COMPLETED]

        # å†™å…¥ API ä½¿ç”¨ç»Ÿè®¡ä¸æ—¥å¿—æ–‡ä»¶
        report.set_api_usage(ai.usage_stats)
        json_path = report.save_json(self.log_dir)
        txt_path = report.save_txt_moves(self.log_dir)

        print("\n" + report.summary_text())
        print(f"\nğŸ§¾ JSON è¯¦æƒ…: {json_path}")
        print(f"ğŸ“„ TXT æ¸…å•: {txt_path}")

        if dry_run:
            print("\nğŸ§¾ æœ¬æ¬¡ä¸º dry-runï¼ˆæœªç§»åŠ¨æ–‡ä»¶ï¼‰ã€‚å°†è‡ªåŠ¨æ‰“å¼€ JSON ä¾›ä½ æ ¸å¯¹ã€‚")
            self._open_file(Path(json_path))

            while True:
                print("\nä¸‹ä¸€æ­¥ï¼š")
                print("  y) æˆ‘å·²æ ¸å¯¹ï¼Œç«‹å³æŒ‰è¯¥ JSON æ‰§è¡Œç§»åŠ¨")
                print('  a) åœ¨ç»ˆç«¯æ˜¾ç¤ºâ€œè®¡åˆ’ç§»åŠ¨æ‘˜è¦â€(æ¯ä¸ªåˆ†ç±»æ–‡ä»¶å¤¹å¤šå°‘ä¸ª)')
                print("  n) é€€å‡ºï¼ˆä»…ä¿ç•™æ¸…å•ï¼Œä¸ç§»åŠ¨ï¼‰")
                ans = input("è¯·é€‰æ‹© (y/a/n) [é»˜è®¤ n]: ").strip().lower() or "n"

                if ans == "a":
                    summ = _plan_summary(completed)
                    if not summ:
                        print("ï¼ˆæ—  planned_to è®°å½•ï¼šå¯èƒ½å…¨éƒ¨ä½ç½®ä¿¡åº¦/å¤±è´¥ï¼‰")
                    else:
                        print("\nè®¡åˆ’ç§»åŠ¨æ‘˜è¦ï¼š")
                        for folder, cnt in sorted(summ.items(), key=lambda x: x[1], reverse=True):
                            print(f"  ğŸ“‚ {folder}: {cnt} ä¸ª")
                    continue

                if ans == "y":
                    # å¤ç”¨ applyï¼šæŒ‰æœ¬æ¬¡ json ç›´æ¥æ‰§è¡Œï¼Œä¸é‡è·‘AI
                    code = self.apply_moves_from_log(str(json_path))
                    return code

                if ans == "n":
                    break

                print("âŒ æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡è¯•ã€‚")

        self.logger.info(f"ä»»åŠ¡å®Œæˆ: total={len(docs)} seconds={dur:.1f} json={json_path} txt={txt_path}")
        return 0