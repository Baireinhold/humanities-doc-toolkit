# -*- coding: utf-8 -*-
from __future__ import annotations

"""
Renamer Engine (Humanities Doc Toolkit)

è¿ç§»ä¸å¢å¼ºè¯´æ˜ï¼š
- æ ¸å¿ƒæµç¨‹æ¥è‡ªä½ ç¨³å®šçš„ DocumentRenamerEnhancedï¼šæ‰«æPDF -> æŠ½å–æ–‡æœ¬ -> AIæå–å…ƒä¿¡æ¯(JSON) -> æŒ‰æ¨¡æ¿ç”Ÿæˆæ–‡ä»¶å -> åˆ†ç±»ç§»åŠ¨/åŸåœ°é‡å‘½å [3]ã€‚
- ä¿ç•™ä¸­æ–‡äº¤äº’ä¸ç¾åŒ–è¾“å‡ºï¼ˆcoloramaï¼‰ã€å¤šçº¿ç¨‹+å¤škeyè½®è¯¢ï¼ˆAPIKeyManageré˜Ÿåˆ—ï¼‰[3]ã€‚
- æ‰©å±•AIæä¾›å•†å…¼å®¹ï¼šClaude / OpenAI / Gemini / DeepSeek / Kimi / GLMã€‚
- ä»æ”¯æŒâ€œåˆ†ç±»æ¨¡å¼(category)â€ä¸â€œåŸåœ°é‡å‘½å(rename_only)â€ä¸¤ç§æ¨¡å¼ï¼Œå¹¶åˆ›å»º å¤„ç†æˆåŠŸ/å¤„ç†å¤±è´¥/é—®é¢˜æ–‡ä»¶ å­ç›®å½• [3]ã€‚
"""

import os
import sys
import re
import json
import time
import yaml
import gc
import shutil
import queue
import logging
import argparse
import threading
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple, Any

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from tqdm import tqdm
import fitz  # PyMuPDF
from colorama import init, Fore, Style
import psutil

init(autoreset=True)

# ---------------------------
# API Key Manager (ç¨³å®šè·¯å¾„)
# ---------------------------
class APIKeyManager:
    """APIå¯†é’¥ç®¡ç†å™¨ - æ”¯æŒå¤šçº¿ç¨‹è½®è¯¢ï¼ˆé˜Ÿåˆ—å–ç”¨/å½’è¿˜ï¼‰[3]"""

    def __init__(self, service_config: Dict[str, Any]):
        self.service_config = service_config
        self.available_keys = [k for k in service_config.get("api_keys", []) if k.get("enabled", False)]
        self.key_queue: "queue.Queue[Dict[str, Any]]" = queue.Queue()
        self.key_stats = defaultdict(lambda: {"calls": 0, "errors": 0, "last_used": None})
        self.token_stats = defaultdict(lambda: {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0})
        for k in self.available_keys:
            self.key_queue.put(k)

    def get_key(self) -> Optional[Dict[str, Any]]:
        try:
            return self.key_queue.get_nowait()
        except queue.Empty:
            return None

    def return_key(self, key_config: Dict[str, Any], success: bool = True):
        key_name = key_config.get("name", "unknown")
        self.key_stats[key_name]["calls"] += 1
        self.key_stats[key_name]["last_used"] = datetime.now()
        if not success:
            self.key_stats[key_name]["errors"] += 1
        self.key_queue.put(key_config)

    def record_token_usage(self, key_name: str, input_tokens: int, output_tokens: int, total_tokens: int):
        self.token_stats[key_name]["input_tokens"] += input_tokens or 0
        self.token_stats[key_name]["output_tokens"] += output_tokens or 0
        self.token_stats[key_name]["total_tokens"] += total_tokens or 0

    def get_stats(self) -> Dict[str, Any]:
        return dict(self.key_stats)

    def get_token_stats(self) -> Dict[str, Any]:
        return dict(self.token_stats)


# ---------------------------
# Renamer Engine
# ---------------------------
class DocumentRenamerEnhanced:
    """æ™ºèƒ½PDFé‡å‘½åå·¥å…·ï¼ˆè¿ç§»å¢å¼ºç‰ˆï¼‰[3]"""

    def __init__(self, global_config_path: str = "global.yaml", renamer_config_path: str = "renamer.yaml"):
        self.version = "0.1"
        self.author = "Baireinhold"
        self.global_config_path = global_config_path
        self.renamer_config_path = renamer_config_path

        self.config = self.load_and_merge_config()
        self.logger = self.setup_logging()

        self.stats = {
            "processed": 0,
            "successful": 0,
            "failed": 0,
            "skipped": 0,
            "problem_docs": 0,
            "start_time": None,
            "api_calls": 0,
            "thread_stats": defaultdict(int),
        }

        self.duplicate_tracker = defaultdict(int)
        self.api_managers: Dict[str, APIKeyManager] = {}
        self.processing_log: List[Dict[str, Any]] = []

        self.session = self._build_requests_session()

        self.ensure_directories()
        self.show_banner()
        self.show_config_info()

    # ---------------------------
    # Config & Logging
    # ---------------------------
    def load_yaml(self, path: str) -> Dict[str, Any]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f) or {}
        if not isinstance(data, dict):
            raise ValueError(f"é…ç½®æ–‡ä»¶æ ¼å¼å¿…é¡»ä¸ºdict: {path}")
        return data

    def deep_merge(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        out = dict(base)
        for k, v in override.items():
            if k in out and isinstance(out[k], dict) and isinstance(v, dict):
                out[k] = self.deep_merge(out[k], v)
            else:
                out[k] = v
        return out

    def load_and_merge_config(self) -> Dict[str, Any]:
        g = self.load_yaml(self.global_config_path)
        r = self.load_yaml(self.renamer_config_path)
        merged = self.deep_merge(g, r)

        # æœ€å°å­—æ®µæ ¡éªŒï¼šai_services.services å¿…é¡»å­˜åœ¨ [2]
        ai_services = merged.get("ai_services", {})
        if not isinstance(ai_services, dict) or not isinstance(ai_services.get("services", {}), dict):
            raise ValueError("global.yaml ç¼ºå°‘ ai_services.services é…ç½® [2]")

        return merged

    def setup_logging(self) -> logging.Logger:
        log_level = "INFO"
        logger = logging.getLogger("hdt-renamer")
        logger.setLevel(getattr(logging, log_level, logging.INFO))
        logger.handlers.clear()
        handler = logging.StreamHandler(sys.stdout)
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
        return logger

    def _build_requests_session(self) -> requests.Session:
        s = requests.Session()
        retry = Retry(total=2, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=20)
        s.mount("http://", adapter)
        s.mount("https://", adapter)
        return s

    # ---------------------------
    # UI / Banner
    # ---------------------------
    def show_banner(self):
        from ..__about__ import __title__, __version__, __author__, __email__, __github__
        banner = f"""
    {Fore.CYAN}{'='*72}
    {Fore.YELLOW}ğŸ“š {__title__} - Renamer v{__version__}
    {Fore.GREEN}ğŸ¤– AIè¾…åŠ© PDF é‡å‘½å/æ ‡å‡†åŒ– (äººæ–‡å­¦ç§‘å‹å¥½å‘½åè§„èŒƒ)
    {Fore.BLUE}ğŸ‘¨â€ğŸ’» ä½œè€…: {__author__} | {__email__}
    {Fore.MAGENTA}ğŸ”— {__github__}
    {Fore.WHITE}æç¤º:
    - é»˜è®¤ä¼šè¯»å– global.yaml + renamer.yaml (å…±äº« ai_services; å·¥å…·å·®å¼‚é…ç½®) [2]
    - è¯·å‹¿æäº¤çœŸå® API Keyï¼›ä»…æäº¤ example é…ç½® [2]
    {'='*72}{Style.RESET_ALL}
    """
        print(banner)

    def show_config_info(self):
        try:
            perf = self.config.get("processing", {}).get("performance", {})
            max_workers = perf.get("max_workers", 8)
            print("ğŸ”§ é…ç½®ä¿¡æ¯:")
            print(f"ğŸ“‹ æœ€å¤§å·¥ä½œçº¿ç¨‹: {max_workers}")

            active_service = self.config.get("ai_services", {}).get("active_service", "deepseek")
            services = self.config.get("ai_services", {}).get("services", {})
            if active_service in services:
                api_keys = services[active_service].get("api_keys", [])
                enabled_count = len([k for k in api_keys if k.get("enabled", False)])
                print(f"ğŸ¤– å½“å‰AIæœåŠ¡: {active_service}")
                print(f"ğŸ”‘ å¯ç”¨APIå¯†é’¥: {enabled_count}/{len(api_keys)}")
            print("âœ… é…ç½®åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ é…ç½®ä¿¡æ¯æ˜¾ç¤ºå¤±è´¥: {e}")

    # ---------------------------
    # Directories
    # ---------------------------
    def ensure_directories(self):
        # Renamer æœ¬èº«åªéœ€è¦ logs/output/backupï¼›ä½ åœ¨æ—§ç‰ˆ config.yaml ä¸­æœ‰ directories.paths [2]
        paths = self.config.get("directories", {}).get("paths", {})
        for _, p in paths.items():
            try:
                if p:
                    Path(p).mkdir(parents=True, exist_ok=True)
            except Exception:
                pass

    # ---------------------------
    # Interactive choices (ä¸­æ–‡)
    # ---------------------------
    def select_ai_service(self) -> str:
        services = self.config["ai_services"]["services"]
        available = []

        print(f"\n{Fore.CYAN}ğŸ¤– å¯ç”¨AIæœåŠ¡:")
        for i, (name, cfg) in enumerate(services.items(), 1):
            api_keys = cfg.get("api_keys", [])
            enabled_keys = [k for k in api_keys if k.get("enabled", False)]
            enabled_count = len(enabled_keys)

            if cfg.get("enabled", False) and enabled_count > 0:
                status = f"{Fore.GREEN}âœ… å¯ç”¨"
                available.append(name)
                self.api_managers[name] = APIKeyManager(cfg)  # ä½¿ç”¨ç¨³å®šçš„é˜Ÿåˆ—è½®è¯¢ [3]
            else:
                status = f"{Fore.RED}âŒ ä¸å¯ç”¨"

            emoji = {
                "deepseek": "ğŸ”",
                "openai": "ğŸ§ ",
                "gemini": "ğŸ¯",
                "claude": "ğŸ’¡",
                "kimi": "ğŸŒ™",
                "glm": "ğŸ§¬",
            }.get(name, "ğŸ¤–")

            print(f"  {i}. {emoji} {name} - {status} ({enabled_count}ä¸ªå¯†é’¥)")

        if not available:
            print(f"{Fore.RED}âŒ æ²¡æœ‰å¯ç”¨AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥ global.yaml çš„ ai_services.services é…ç½® [2]")
            sys.exit(1)

        # é»˜è®¤ä½¿ç”¨ active_service
        default_service = self.config.get("ai_services", {}).get("active_service", available[0])
        if default_service in available:
            default_idx = list(services.keys()).index(default_service) + 1
        else:
            default_idx = 1

        while True:
            choice = input(f"\n{Fore.YELLOW}ğŸ¯ è¯·é€‰æ‹©AIæœåŠ¡ (1-{len(services)}) [é»˜è®¤{default_idx}]: {Style.RESET_ALL}").strip()
            if not choice:
                picked = list(services.keys())[default_idx - 1]
                if picked in available:
                    print(f"{Fore.GREEN}âœ… å·²é€‰æ‹©: {picked}{Style.RESET_ALL}")
                    return picked
                picked = available[0]
                print(f"{Fore.GREEN}âœ… å·²é€‰æ‹©: {picked}{Style.RESET_ALL}")
                return picked
            try:
                idx = int(choice) - 1
                picked = list(services.keys())[idx]
                if picked in available:
                    print(f"{Fore.GREEN}âœ… å·²é€‰æ‹©: {picked}{Style.RESET_ALL}")
                    return picked
                print(f"{Fore.RED}âŒ è¯¥æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·é‡æ–°é€‰æ‹©ã€‚{Style.RESET_ALL}")
            except Exception:
                print(f"{Fore.RED}âŒ æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥æ•°å­—ã€‚{Style.RESET_ALL}")

    def get_processing_pages(self) -> Tuple[int, int]:
        extraction = self.config.get("processing", {}).get("extraction", {})
        default_start = int(extraction.get("start_page", 1))
        default_end = int(extraction.get("end_page", 10))

        print(f"\n{Fore.CYAN}ğŸ“„ é¡µé¢èŒƒå›´è®¾ç½®:")
        print(f"ğŸ“‹ é»˜è®¤èŒƒå›´: {default_start}-{default_end} é¡µ")
        s = input(f"{Fore.YELLOW}ğŸ“ è¾“å…¥èµ·å§‹é¡µ(å›è½¦é»˜è®¤{default_start}): {Style.RESET_ALL}").strip()
        e = input(f"{Fore.YELLOW}ğŸ“ è¾“å…¥ç»“æŸé¡µ(å›è½¦é»˜è®¤{default_end}): {Style.RESET_ALL}").strip()
        try:
            start_page = int(s) if s else default_start
            end_page = int(e) if e else default_end
            if start_page < 1:
                start_page = 1
            if end_page < start_page:
                end_page = start_page
            return start_page, end_page
        except Exception:
            print(f"{Fore.YELLOW}âš ï¸ è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤èŒƒå›´ã€‚{Style.RESET_ALL}")
            return default_start, default_end

    def get_output_directory(self) -> str:
        default_output = self.config.get("directories", {}).get("paths", {}).get("output", "output")
        print(f"\n{Fore.CYAN}ğŸ“‚ è¾“å‡ºç›®å½•é…ç½®:")
        print(f"ğŸ“ é»˜è®¤è¾“å‡ºç›®å½•: {default_output}")
        user = input(f"{Fore.YELLOW}ğŸ¯ è¾“å…¥è¾“å‡ºç›®å½•(å›è½¦é»˜è®¤): {Style.RESET_ALL}").strip()
        out = user or default_output
        Path(out).mkdir(parents=True, exist_ok=True)
        return str(Path(out).absolute())

    def get_processing_mode(self) -> str:
        print(f"\n{Fore.CYAN}ğŸ”§ å¤„ç†æ¨¡å¼:")
        print("  1. ğŸ“‚ åˆ†ç±»æ¨¡å¼ï¼šåˆ›å»ºå­æ–‡ä»¶å¤¹ï¼ˆå¤„ç†æˆåŠŸ/å¤„ç†å¤±è´¥/é—®é¢˜æ–‡ä»¶ï¼‰[3]")
        print("  2. ğŸ”„ åŸåœ°é‡å‘½åï¼šä¿æŒåŸä½ç½®ç›´æ¥é‡å‘½å[3]")
        while True:
            c = input(f"{Fore.YELLOW}è¯·é€‰æ‹© (1/2) [é»˜è®¤1]: {Style.RESET_ALL}").strip() or "1"
            if c == "1":
                return "category"
            if c == "2":
                return "rename_only"
            print(f"{Fore.RED}âŒ è¯·è¾“å…¥ 1 æˆ– 2{Style.RESET_ALL}")

    # ---------------------------
    # Output folders
    # ---------------------------
    def setup_output_folders(self, output_dir: str) -> Dict[str, str]:
        subfolder_names = self.config.get("output_management", {}).get("subfolder_names", {
            "success": "å¤„ç†æˆåŠŸ",
            "failed": "å¤„ç†å¤±è´¥",
            "problem": "é—®é¢˜æ–‡ä»¶"
        })
        folders = {
            "success": os.path.join(output_dir, subfolder_names["success"]),
            "failed": os.path.join(output_dir, subfolder_names["failed"]),
            "problem": os.path.join(output_dir, subfolder_names["problem"]),
        }
        for k, p in folders.items():
            try:
                Path(p).mkdir(parents=True, exist_ok=True)
            except Exception as e:
                self.logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥ {k}: {p} - {e}")
                folders[k] = output_dir
        return folders

    def move_file_to_category(self, source_path: str, target_folder: str, final_filename: str) -> str:
        target_path = os.path.join(target_folder, final_filename)
        counter = 1
        while os.path.exists(target_path):
            stem, ext = os.path.splitext(final_filename)
            target_path = os.path.join(target_folder, f"{stem}_{counter}{ext}")
            counter += 1

        # åŒç›®å½• renameï¼Œä¸åŒç›®å½• move
        src_dir = os.path.dirname(source_path)
        dst_dir = os.path.dirname(target_path)
        if os.path.abspath(src_dir) == os.path.abspath(dst_dir):
            os.rename(source_path, target_path)
        else:
            shutil.move(source_path, target_path)
        return target_path

    # ---------------------------
    # File scanning & PDF extract
    # ---------------------------
    def find_pdf_files(self, directory: str) -> List[str]:
        allowed_ext = self.config.get("directories", {}).get("file_filtering", {}).get("allowed_extensions", [".pdf"])
        pdfs = []
        seen = set()
        for root, _, files in os.walk(directory):
            for fn in files:
                fn_low = fn.lower()
                if any(fn_low.endswith(ext.lower()) for ext in allowed_ext):
                    p = os.path.join(root, fn)
                    key = os.path.normpath(p).lower()
                    if key not in seen:
                        seen.add(key)
                        pdfs.append(p)
        print(f"{Fore.GREEN}âœ… å‘ç° {len(pdfs)} ä¸ªPDFæ–‡ä»¶{Style.RESET_ALL}")
        return pdfs

    def extract_text_from_pdf(self, file_path: str, start_page: int, end_page: int) -> str:
        try:
            doc = fitz.open(file_path)
            parts = []
            actual_end = min(end_page, doc.page_count)
            for page_num in range(start_page - 1, actual_end):
                text = doc[page_num].get_text()
                if text and text.strip():
                    parts.append(text.strip())
            doc.close()
            extracted = "\n".join(parts)

            if not extracted or len(extracted.strip()) < 10:
                return "NEEDS_OCR_PROCESSING"

            max_len = int(self.config.get("processing", {}).get("extraction", {}).get("max_text_length", 10000))
            if len(extracted) > max_len:
                extracted = extracted[:max_len] + "..."
            return extracted
        except Exception as e:
            self.logger.error(f"PDFæå–å¤±è´¥: {file_path}: {e}")
            return "NEEDS_OCR_PROCESSING"

    # ---------------------------
    # AI calling: multi-provider
    # ---------------------------
    def _parse_usage_tokens(self, response_json: Dict[str, Any]) -> Tuple[int, int, int]:
        usage = response_json.get("usage") if isinstance(response_json, dict) else None
        if not usage or not isinstance(usage, dict):
            return 0, 0, 0
        in_t = usage.get("prompt_tokens", 0) or usage.get("input_tokens", 0) or 0
        out_t = usage.get("completion_tokens", 0) or usage.get("output_tokens", 0) or 0
        total = usage.get("total_tokens", 0) or (in_t + out_t)
        return int(in_t), int(out_t), int(total)

    def call_ai_service(self, text: str, service_name: str) -> Optional[Dict[str, Any]]:
        api_manager = self.api_managers.get(service_name)
        if not api_manager:
            self.logger.error(f"æœªæ‰¾åˆ° {service_name} çš„APIç®¡ç†å™¨")
            return None

        # è·å– key(çŸ­æš‚é‡è¯•)
        api_key_cfg = None
        for _ in range(3):
            api_key_cfg = api_manager.get_key()
            if api_key_cfg:
                break
            time.sleep(0.1)
        if not api_key_cfg:
            self.logger.error(f"{service_name} æ²¡æœ‰å¯ç”¨APIå¯†é’¥")
            return None

        service_cfg = self.config["ai_services"]["services"][service_name]
        base_url = service_cfg.get("base_url", "").strip()
        model = service_cfg.get("model", "")
        timeout = int(self.config.get("ai_services", {}).get("api_request_timeout", 30))

        # ---------- è¯­è¨€ç­–ç•¥(æ¥è‡ª renamer.yaml çš„ ai_text_policy.language) ----------
        lang_cfg = self.config.get("ai_text_policy", {}).get("language", {}) if isinstance(self.config.get("ai_text_policy", {}), dict) else {}
        mode = str(lang_cfg.get("mode", "keep_original")).strip().lower()  # keep_original | translate
        target = str(lang_cfg.get("target", "")).strip()  # zh/en/ja...
        fields = lang_cfg.get("fields", ["title", "publisher", "journal"])
        if not isinstance(fields, list) or not fields:
            fields = ["title", "publisher", "journal"]

        allowed_fields = {"title", "publisher", "journal"}
        fields = [f for f in fields if isinstance(f, str) and f.strip().lower() in allowed_fields]
        fields = [f.strip().lower() for f in fields] or ["title", "publisher", "journal"]

        if mode not in {"keep_original", "translate"}:
            mode = "keep_original"
        if mode == "translate" and not target:
            # translate ä½†æœªæä¾› targetï¼Œå›é€€ä¸ºä¿æŒåŸæ–‡
            mode = "keep_original"

        if mode == "keep_original":
            lang_instruction = (
                "è¯­è¨€è¦æ±‚ï¼šè¯·ä¿æŒä»¥ä¸‹å­—æ®µçš„åŸå§‹è¯­è¨€ï¼Œä¸è¦ç¿»è¯‘ï¼š"
                f"{', '.join(fields)}ã€‚"
                "author å­—æ®µæ°¸è¿œä¸è¦ç¿»è¯‘ï¼Œä¿æŒåŸæ ·ã€‚"
            )
        else:
            # translate
            lang_instruction = (
                f"è¯­è¨€è¦æ±‚ï¼šè¯·å°†ä»¥ä¸‹å­—æ®µç¿»è¯‘ä¸º {target} è¯­è¨€ï¼š{', '.join(fields)}ã€‚"
                "author å­—æ®µæ°¸è¿œä¸è¦ç¿»è¯‘ï¼Œä¿æŒåŸæ ·ã€‚"
                "å¦‚æœåŸå­—æ®µå·²ç»æ˜¯ç›®æ ‡è¯­è¨€ï¼Œå¯ä¿æŒä¸å˜ã€‚"
            )

        # è¾“å…¥æˆªæ–­ï¼ˆå­—ç¬¦æ•°ï¼Œä¸æ˜¯ token ä¸Šé™ï¼‰ï¼›è¾“å‡º token ä¸Šé™æ¥è‡ª global.yaml max_tokens [2]
        max_chars = int(self.config.get("processing", {}).get("extraction", {}).get("prompt_text_max_chars", 2000))
        preview = (text or "")[:max_chars]

        # ---------- Promptï¼ˆä¿æŒä¸¥æ ¼ JSON ä¸ç±»å‹çº¦æŸï¼‰ ----------
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹PDFæ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼å›å¤ï¼ŒåŒ…å«å­—æ®µï¼š
- title: æ–‡æ¡£æ ‡é¢˜ï¼ˆä¸è¦åŒ…å«ä¸‹åˆ’çº¿_ï¼Œå¯ç”¨ç ´æŠ˜å·-ï¼‰
- author: ä½œè€…å§“åï¼ˆä¸ç¡®å®šåˆ™ç©ºå­—ç¬¦ä¸²ï¼›æ³¨æ„ï¼šauthor ä¸è¦ç¿»è¯‘ï¼‰
- year: å•ä¸€4ä½å‡ºç‰ˆå¹´ä»½ï¼ˆä¸ç¡®å®šåˆ™ç©ºå­—ç¬¦ä¸²ï¼‰
- type: æ–‡æ¡£ç±»å‹ï¼Œå¿…é¡»æ˜¯ book / paper / others / unknown
- journal: æœŸåˆŠåï¼ˆpaperéœ€è¦ï¼Œå…¶ä»–ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
- publisher: å‡ºç‰ˆç¤¾ï¼ˆbookéœ€è¦ï¼Œå…¶ä»–ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰

é‡è¦è¦æ±‚ï¼š
1) type å¿…é¡»å››é€‰ä¸€ï¼Œé»˜è®¤å€¾å‘ others
2) ä¸è¦è¾“å‡ºé™¤JSONä¹‹å¤–çš„ä»»ä½•æ–‡å­—
3) æ— æ³•ç¡®å®šå­—æ®µç”¨ ""ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰ï¼Œä¸è¦å†™â€œæœªçŸ¥/ä¸è¯¦â€
4) {lang_instruction}

æ–‡æ¡£å†…å®¹ï¼š
{preview}
""".strip()

        success = False
        result: Optional[Dict[str, Any]] = None

        try:
            # 1) Claude
            if service_name.lower() == "claude" or "anthropic" in base_url:
                headers = {
                    "x-api-key": api_key_cfg["key"],
                    "anthropic-version": "2023-06-01",
                    "content-type": "application/json",
                }
                payload = {
                    "model": model or "claude-3-haiku-20240307",
                    "max_tokens": int(service_cfg.get("max_tokens", 500)),
                    "temperature": float(service_cfg.get("temperature", 0.1)),
                    "messages": [{"role": "user", "content": prompt}],
                }
                resp = self.session.post(base_url, headers=headers, json=payload, timeout=timeout)
                if resp.status_code != 200:
                    raise RuntimeError(f"Claudeè°ƒç”¨å¤±è´¥: {resp.status_code} {resp.text[:200]}")
                data = resp.json()
                content = ""
                if isinstance(data.get("content"), list) and data["content"]:
                    content = data["content"][0].get("text", "").strip()
                result = self._safe_json_from_model_text(content)

            # 2) Gemini
            elif service_name.lower() == "gemini" or "generativelanguage.googleapis.com" in base_url:
                url = base_url
                if "key=" not in url:
                    joiner = "&" if "?" in url else "?"
                    url = f"{url}{joiner}key={api_key_cfg['key']}"
                payload = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {
                        "temperature": float(service_cfg.get("temperature", 0.1)),
                        "maxOutputTokens": int(service_cfg.get("max_tokens", 500)),
                    },
                }
                resp = self.session.post(url, json=payload, timeout=timeout)
                if resp.status_code != 200:
                    raise RuntimeError(f"Geminiè°ƒç”¨å¤±è´¥: {resp.status_code} {resp.text[:200]}")
                data = resp.json()
                content = ""
                try:
                    content = data["candidates"][0]["content"]["parts"][0]["text"].strip()
                except Exception:
                    content = ""
                result = self._safe_json_from_model_text(content)

            # 3) OpenAI-compatible
            else:
                headers = {"Authorization": f"Bearer {api_key_cfg['key']}", "Content-Type": "application/json"}
                payload = {
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": int(service_cfg.get("max_tokens", 2000)),
                    "temperature": float(service_cfg.get("temperature", 0.1)),
                }
                resp = self.session.post(base_url, headers=headers, json=payload, timeout=timeout)
                if resp.status_code != 200:
                    raise RuntimeError(f"{service_name}è°ƒç”¨å¤±è´¥: {resp.status_code} {resp.text[:200]}")
                data = resp.json()

                # tokenç»Ÿè®¡ï¼ˆä¿ç•™ä½ åŸé€»è¾‘ï¼‰[17]
                in_t, out_t, total = self._parse_usage_tokens(data)
                api_manager.record_token_usage(api_key_cfg.get("name", "unknown"), in_t, out_t, total)

                content = data["choices"][0]["message"]["content"].strip()
                result = self._safe_json_from_model_text(content)

            if result:
                result = self._normalize_ai_result(result)
                success = True
                self.stats["api_calls"] += 1

        except Exception as e:
            self.logger.error(f"AIè°ƒç”¨å¼‚å¸¸({service_name}): {e}")
            success = False
            result = None
        finally:
            api_manager.return_key(api_key_cfg, success)

        return result

    def _safe_json_from_model_text(self, content: str) -> Optional[Dict[str, Any]]:
        if not content:
            return None
        c = content.strip()
        # å»æ‰ ```json åŒ…è£¹ [3]
        if c.startswith("```"):
            c = re.sub(r"^```[a-zA-Z]*\n", "", c).strip()
            c = c.rstrip("`").strip()
        # æå– JSON
        if not (c.startswith("{") and c.endswith("}")):
            m = re.search(r"\{.*\}", c, re.DOTALL)
            if m:
                c = m.group(0)
        try:
            obj = json.loads(c)
            return obj if isinstance(obj, dict) else None
        except Exception:
            self.logger.warning(f"AIè¿”å›éJSON: {content[:120]}")
            return None

    def _normalize_ai_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        # year: æå–4ä½å¹´ä»½æˆ–ç½®ç©º
        year = str(result.get("year", "")).strip()
        if any(w in year.lower() for w in ["æœªçŸ¥", "unknown", "ä¸è¯¦", "n/a", "none"]):
            result["year"] = ""
        else:
            m = re.search(r"\b(19|20)\d{2}\b", year)
            result["year"] = m.group(0) if m else ""

        # author/title/journal/publisherï¼šæœªçŸ¥ç½®ç©ºï¼›titleè‹¥ç©ºè§†ä¸ºé—®é¢˜æ–‡æ¡£
        def clean_text(v: Any) -> str:
            s = str(v or "").strip().replace("_", "-")
            if any(w in s.lower() for w in ["æœªçŸ¥", "unknown", "ä¸è¯¦", "n/a", "none"]):
                return ""
            return s

        result["author"] = clean_text(result.get("author", ""))
        result["journal"] = clean_text(result.get("journal", ""))
        result["publisher"] = clean_text(result.get("publisher", ""))

        title = clean_text(result.get("title", ""))
        if not title:
            result["title"] = "æœªçŸ¥"
            result["is_problem_doc"] = True
        else:
            result["title"] = title
            result["is_problem_doc"] = False

        # type é™å®š
        t = str(result.get("type", "others")).strip().lower()
        if t not in {"book", "paper", "others", "unknown"}:
            t = "others"
        result["type"] = t
        return result

    # ---------------------------
    # Naming rules (ä¿ç•™ä½ æ ¸å¿ƒå‘½åèƒ½åŠ›) [2][3]
    # ---------------------------
    def apply_case_rule(self, text: str) -> str:
        if not text:
            return text
        case_style = self.config.get("file_naming", {}).get("filename_rules", {}).get("case_style", "title")
        if case_style == "title":
            return " ".join(w.capitalize() for w in text.split())
        if case_style == "upper":
            return text.upper()
        if case_style == "lower":
            return text.lower()
        return text

    def generate_filename(self, info: Dict[str, Any], doc_type: str, original_stem: Optional[str] = None) -> str:
        # é—®é¢˜æ–‡æ¡£ï¼šç›´æ¥ä¿ç•™åŸæ–‡ä»¶åå¹¶åŠ å‰ç¼€ [3]
        if info.get("is_problem_doc") and original_stem:
            return f"[å¾…å¤„ç†]{original_stem}"

        patterns = self.config.get("file_naming", {}).get("naming_patterns", {})
        pattern = patterns.get(doc_type, patterns.get("others", "{title}_{year}"))  # ä½ é…ç½®ä¸­é»˜è®¤others [2]

        defaults = self.config.get("file_naming", {}).get("default_values", {
            "title": "",
            "author": "",
            "year": "",
            "publisher": "",
            "journal": "",
            "timestamp": "{datetime}",
        })

        processed = dict(info)
        for k, dv in defaults.items():
            if not processed.get(k):
                if k == "timestamp":
                    processed[k] = datetime.now().strftime("%Y%m%d_%H%M%S")
                else:
                    processed[k] = ""

        # year å…œåº•ï¼šç”¨å½“å‰å¹´ä»½
        if not processed.get("year"):
            processed["year"] = datetime.now().strftime("%Y")

        for k in ["title", "author", "journal", "publisher"]:
            if processed.get(k):
                processed[k] = self.apply_case_rule(processed[k])

        try:
            filename = pattern.format(**processed)
        except Exception as e:
            self.logger.warning(f"æ¨¡æ¿æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨å®‰å…¨æ ¼å¼: {e}")
            filename = f"{processed.get('author','')}_{processed.get('title','æ–‡æ¡£')}_{processed.get('year','')}".strip("_")

        filename = self.clean_filename(filename)
        if not filename or filename.strip() in {"", "_", "-"}:
            filename = f"æ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        return self.handle_duplicate_filename(filename)

    def clean_filename(self, filename: str) -> str:
        rules = self.config.get("file_naming", {}).get("filename_rules", {})
        max_length = int(rules.get("max_length", 200))

        has_problem = filename.startswith("[å¾…å¤„ç†]")
        clean_part = filename[5:] if has_problem else filename

        replacements = {
            ":": "-",
            "ï¼š": "-",
            "<": "ã€Š",
            ">": "ã€‹",
            "|": "_",
            "?": "",
            "*": "",
            "/": "_",
            "\\": "_",
        }
        for old, new in replacements.items():
            clean_part = clean_part.replace(old, new)

        if rules.get("normalize_spaces", True):
            clean_part = re.sub(r"\s+", " ", clean_part)
        if rules.get("trim_whitespace", True):
            clean_part = clean_part.strip()

        clean_part = re.sub(r"_+", "_", clean_part)
        clean_part = re.sub(r"^_|_$", "", clean_part)

        out = f"[å¾…å¤„ç†]{clean_part}" if has_problem else clean_part
        if len(out) > max_length:
            out = out[:max_length]
        return out

    def handle_duplicate_filename(self, filename: str) -> str:
        base_name = filename[:-4] if filename.lower().endswith(".pdf") else filename
        counter = self.duplicate_tracker[base_name.lower()]
        if counter > 0:
            suffix_t = self.config.get("file_naming", {}).get("special_handling", {}).get("duplicate_suffix", "_{counter}")
            filename = f"{base_name}{suffix_t.format(counter=counter)}"
        self.duplicate_tracker[base_name.lower()] += 1
        return filename

    # ---------------------------
    # Single-file processing
    # ---------------------------
    def process_single_file(
        self,
        file_path: str,
        service_name: str,
        start_page: int,
        end_page: int,
        output_dir: str,
        processing_mode: str
    ) -> Dict[str, Any]:
        thread_name = threading.current_thread().name
        self.stats["thread_stats"][thread_name] += 1

        result = {
            "file_path": file_path,
            "success": False,
            "new_filename": None,
            "error": None,
            "thread": thread_name,
            "timestamp": datetime.now(),
            "ai_info": None,
            "category": "unknown",
            "final_path": None,
        }

        try:
            text = self.extract_text_from_pdf(file_path, start_page, end_page)

            # OCRæ ‡è®°è·¯å¾„ï¼šæ—§ç‰ˆç”¨ NEEDS_OCR_PROCESSING å¹¶åŠ  [éœ€è¦OCR] å‰ç¼€ [3]
            if text == "NEEDS_OCR_PROCESSING":
                ocr_prefix = self.config.get("file_naming", {}).get("special_handling", {}).get("ocr_prefix", "[éœ€è¦OCR]")
                original = os.path.basename(file_path)
                new_name = f"{ocr_prefix}{original}"
                if processing_mode == "category":
                    final_path = self.move_file_to_category(file_path, self.output_folders["problem"], new_name)
                    result["final_path"] = final_path
                else:
                    # åŸåœ°é‡å‘½å
                    new_path = os.path.join(os.path.dirname(file_path), new_name)
                    if os.path.abspath(new_path) != os.path.abspath(file_path):
                        os.rename(file_path, new_path)
                    result["final_path"] = new_path
                result["success"] = True
                result["new_filename"] = new_name
                result["category"] = "problem"
                result["ai_info"] = {"type": "needs_ocr", "title": "OCRå¤„ç†"}
                return result

            info = self.call_ai_service(text, service_name)
            if not info:
                result["error"] = "AIåˆ†æå¤±è´¥"
                return result

            result["ai_info"] = info
            if info.get("is_problem_doc"):
                self.stats["problem_docs"] += 1

            doc_type = info.get("type", "others")
            original_stem = os.path.splitext(os.path.basename(file_path))[0]
            new_stem = self.generate_filename(info, doc_type, original_stem)
            result["new_filename"] = new_stem

            if processing_mode == "category":
                if info.get("is_problem_doc"):
                    target = self.output_folders["problem"]
                    final_filename = f"[å¾…å¤„ç†]{os.path.basename(file_path)}"
                    result["category"] = "problem"
                else:
                    target = self.output_folders["success"]
                    final_filename = f"{new_stem}.pdf"
                    result["category"] = "success"
                result["final_path"] = self.move_file_to_category(file_path, target, final_filename)
            else:
                # åŸåœ°é‡å‘½å
                file_dir = os.path.dirname(file_path)
                if info.get("is_problem_doc"):
                    final_filename = f"[å¾…å¤„ç†]{os.path.basename(file_path)}"
                    result["category"] = "problem"
                else:
                    final_filename = f"{new_stem}.pdf"
                    result["category"] = "success"

                new_path = os.path.join(file_dir, final_filename)
                counter = 1
                while os.path.exists(new_path) and os.path.abspath(new_path) != os.path.abspath(file_path):
                    stem, ext = os.path.splitext(final_filename)
                    new_path = os.path.join(file_dir, f"{stem}_{counter}{ext}")
                    counter += 1
                if os.path.abspath(new_path) != os.path.abspath(file_path):
                    os.rename(file_path, new_path)
                result["final_path"] = new_path

            result["success"] = True
            return result

        except Exception as e:
            result["success"] = False
            result["error"] = str(e)
            return result

    # ---------------------------
    # Batch processing
    # ---------------------------
    def process_files(
        self,
        input_dir: str,
        service_name: str,
        start_page: int,
        end_page: int,
        output_dir: str,
        processing_mode: str = "category",
    ):
        self.stats["start_time"] = time.time()

        if processing_mode == "category":
            print(f"{Fore.CYAN}ğŸ“ æ­£åœ¨è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹ç»“æ„...{Style.RESET_ALL}")
            self.output_folders = self.setup_output_folders(output_dir)
        else:
            print(f"{Fore.CYAN}ğŸ”„ åŸåœ°é‡å‘½åæ¨¡å¼ï¼šä¿æŒæ–‡ä»¶åŸä½ç½®{Style.RESET_ALL}")
            self.output_folders = None

        pdf_files = self.find_pdf_files(input_dir)
        if not pdf_files:
            print(f"{Fore.YELLOW}ğŸ“‚ æœªæ‰¾åˆ°PDFæ–‡ä»¶: {input_dir}{Style.RESET_ALL}")
            return

        perf = self.config.get("processing", {}).get("performance", {})
        configured_workers = int(perf.get("max_workers", 8))
        available_keys = len(self.api_managers[service_name].available_keys)
        max_workers = max(1, min(configured_workers, available_keys))  # çº¿ç¨‹æ•°<=keyæ•° [3]

        print(f"\n{Fore.BLUE}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.BLUE}ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†{Style.RESET_ALL}")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“„ æ–‡ä»¶æ•°é‡: {len(pdf_files)}")
        print(f"ğŸ“‹ é¡µé¢èŒƒå›´: {start_page}-{end_page}")
        print(f"ğŸ¤– AIæœåŠ¡: {service_name}")
        print(f"ğŸ§µ çº¿ç¨‹æ•°: {max_workers} (é…ç½®:{configured_workers}, å¯†é’¥:{available_keys})")
        print(f"{Fore.BLUE}{'='*60}{Style.RESET_ALL}")

        with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="PDFWorker") as executor:
            futures = {
                executor.submit(self.process_single_file, fp, service_name, start_page, end_page, output_dir, processing_mode): fp
                for fp in pdf_files
            }

            bar = tqdm(
                total=len(pdf_files),
                desc="ğŸ”„ å¤„ç†è¿›åº¦",
                leave=True,
                bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]"
            )

            for future in as_completed(futures):
                fp = futures[future]
                self.stats["processed"] += 1
                try:
                    r = future.result(timeout=120)
                    self.processing_log.append(r)
                    if r.get("success"):
                        self.stats["successful"] += 1
                    else:
                        self.stats["failed"] += 1
                        # åˆ†ç±»æ¨¡å¼ä¸‹ï¼šå¤±è´¥æ–‡ä»¶ç§»å…¥ failed
                        if processing_mode == "category" and self.output_folders:
                            try:
                                failed_name = f"[å¤±è´¥]{os.path.basename(fp)}"
                                self.move_file_to_category(fp, self.output_folders["failed"], failed_name)
                            except Exception:
                                pass
                except Exception as e:
                    self.stats["failed"] += 1
                    self.processing_log.append({"file_path": fp, "success": False, "error": str(e), "timestamp": datetime.now()})
                finally:
                    bar.update(1)

            bar.close()

        gc.collect()
        self.show_statistics()

    def show_statistics(self):
        duration = time.time() - self.stats["start_time"] if self.stats["start_time"] else 0
        print(f"\n{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡{Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {self.stats['processed']}")
        print(f"{Fore.GREEN}âœ… æˆåŠŸ: {self.stats['successful']}{Style.RESET_ALL}")
        print(f"{Fore.RED}âŒ å¤±è´¥: {self.stats['failed']}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}âš ï¸ é—®é¢˜æ–‡æ¡£: {self.stats['problem_docs']}{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}â±ï¸ ç”¨æ—¶: {duration:.2f} ç§’{Style.RESET_ALL}")
        print(f"{Fore.MAGENTA}ğŸ”„ APIè°ƒç”¨: {self.stats['api_calls']}{Style.RESET_ALL}")

        # çº¿ç¨‹ç»Ÿè®¡ä¸èµ„æº
        if self.stats["thread_stats"]:
            print(f"{Fore.CYAN}ğŸ§µ çº¿ç¨‹åˆ†å¸ƒ:{Style.RESET_ALL}")
            for t, c in self.stats["thread_stats"].items():
                print(f"  {t}: {c} ä¸ªæ–‡ä»¶")

        mem = psutil.Process().memory_info().rss / 1024 / 1024
        cpu = psutil.cpu_percent()
        print(f"{Fore.YELLOW}ğŸ’¾ å†…å­˜ä½¿ç”¨: {mem:.1f} MB{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ’» CPUä½¿ç”¨: {cpu:.1f}%{Style.RESET_ALL}")

        # API key/tokenç»Ÿè®¡ï¼ˆä¿ç•™ä½ åŸæœ¬çš„â€œkeyçº§ç»Ÿè®¡â€ï¼‰[3]
        for svc, mgr in self.api_managers.items():
            ks = mgr.get_stats()
            ts = mgr.get_token_stats()
            if ks:
                print(f"{Fore.CYAN}ğŸ”‘ {svc} å¯†é’¥è°ƒç”¨ç»Ÿè®¡:{Style.RESET_ALL}")
                for k, st in ks.items():
                    print(f"  {k}: {st['calls']} æ¬¡è°ƒç”¨, {st['errors']} æ¬¡é”™è¯¯")
            if ts:
                total_tokens = sum(v["total_tokens"] for v in ts.values())
                if total_tokens:
                    print(f"{Fore.CYAN}ğŸ’° {svc} Tokenç»Ÿè®¡: {total_tokens:,} tokens{Style.RESET_ALL}")

        print(f"{Fore.CYAN}{'='*60}{Style.RESET_ALL}")

    # ---------------------------
    # Main interactive run
    # ---------------------------
    def run(self, input_dir: Optional[str] = None, output_dir: Optional[str] = None):
        try:
            if not input_dir:
                input_dir = input(f"{Fore.YELLOW}ğŸ“ è¯·è¾“å…¥PDFæ–‡ä»¶ç›®å½•è·¯å¾„: {Style.RESET_ALL}").strip().strip('"')
            if not input_dir or not os.path.exists(input_dir):
                print(f"{Fore.RED}âŒ ç›®å½•ä¸å­˜åœ¨: {input_dir}{Style.RESET_ALL}")
                return 1

            service_name = self.select_ai_service()
            start_page, end_page = self.get_processing_pages()

            out_dir = output_dir or self.get_output_directory()
            mode = self.get_processing_mode()

            self.process_files(input_dir, service_name, start_page, end_page, out_dir, mode)

            print(f"\n{Fore.CYAN}ğŸ¯ å¤„ç†å®Œæˆ!{Style.RESET_ALL}")
            return 0
        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}âš ï¸ ç”¨æˆ·ä¸­æ–­{Style.RESET_ALL}")
            return 1
        except Exception as e:
            print(f"{Fore.RED}âŒ ç¨‹åºå¼‚å¸¸: {e}{Style.RESET_ALL}")
            return 1


class RenamerEngine:
    """å¯¹å¤–å¼•æ“å°è£…ï¼ˆä¾› hdt-renamer CLI è°ƒç”¨ï¼‰"""

    def __init__(self, global_config: str, tool_config: str):
        self.app = DocumentRenamerEnhanced(global_config, tool_config)

    def run_interactive(self, input_dir: Optional[str] = None, output_dir: Optional[str] = None) -> int:
        return self.app.run(input_dir=input_dir, output_dir=output_dir)